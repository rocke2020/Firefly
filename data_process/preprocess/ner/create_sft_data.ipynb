{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| 857815639.py:33 in read_chem_x_gene()\n",
      "    df_data.columns.to_list(): ['sentence', 'entity_type', 'entity_name', 'entity_ini', 'entity_end', 'text', 'id']\n",
      "ic| 857815639.py:34 in read_chem_x_gene()- df_data.entity_type.unique(): ['Chemical' 'Gene']\n",
      "ic| 857815639.py:36 in read_chem_x_gene()- len(unique_entity_names): 3013\n",
      "ic| 857815639.py:37 in read_chem_x_gene()- 'genes' in df_data.entity_name.unique().tolist(): True\n",
      "ic| 857815639.py:38 in read_chem_x_gene()- 'proteins' in df_data.entity_name.unique().tolist(): True\n",
      "ic| 857815639.py:39 in read_chem_x_gene()- 'chemicals' in df_data.entity_name.unique().tolist(): False\n",
      "ic| 857815639.py:65 in read_chem_x_gene()- len(df_data): 6537, df_data.sentence.nunique(): 1655\n",
      "ic| 857815639.py:218 in <module>- df_data_ner.columns.to_list(): ['sentence', 'entity_info']\n",
      "ic| 857815639.py:221 in <module>- len(df_data_ner): 1655\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from icecream import ic\n",
    "\n",
    "ic.configureOutput(includeContext=True, argToStringFunction=str)\n",
    "ic.lineWrapWidth = 120\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "punc_at_ends = re.compile(r'^\\W+|\\W+$')\n",
    "\n",
    "\n",
    "def read_chem_x_gene():\n",
    "    \"\"\"  \"\"\"\n",
    "    file = Path('/mnt/nas1/corpus-bio-nlp/NER/PGx_CTD_chem_x_gene.csv')\n",
    "    df_data = pd.read_csv(file)\n",
    "    ic(df_data.columns.to_list())\n",
    "    ic(df_data.entity_type.unique())\n",
    "    unique_entity_names = df_data.entity_name.unique().tolist()\n",
    "    ic(len(unique_entity_names))\n",
    "    ic('genes' in df_data.entity_name.unique().tolist())\n",
    "    ic('proteins' in df_data.entity_name.unique().tolist())\n",
    "    ic('chemicals' in df_data.entity_name.unique().tolist())\n",
    "\n",
    "    # check short general entities\n",
    "    possible_general_entities = []\n",
    "    short_general_entities = ['gene', 'protein', 'chemical', 'drug']\n",
    "    for short_entity in short_general_entities:\n",
    "        for unique_entity in unique_entity_names:\n",
    "            if short_entity in unique_entity:\n",
    "                possible_general_entities.append(unique_entity)\n",
    "    possible_general_entities = sorted(possible_general_entities, key=lambda x: len(x.split()))\n",
    "    possible_general_entities_file = 'possible_general_entities_file.log'\n",
    "    with open(possible_general_entities_file, 'w') as f:\n",
    "        f.write('\\n'.join(possible_general_entities))\n",
    "\n",
    "    # filter general entities, not filter drup\n",
    "    # general_entities = ['genes', 'proteins', 'multidrug', 'drug']\n",
    "    general_entities = ['genes', 'proteins']\n",
    "    df_data = df_data[~df_data.entity_name.isin(general_entities)]\n",
    "    df_data.rename(columns={\"id\": \"uid\"}, inplace=True)\n",
    "\n",
    "    # save and check uid contains pgx_\n",
    "    # _df_data = df_data[df_data[\"uid\"].str.contains(\"pgx_\")]\n",
    "    # ic(len(_df_data))\n",
    "    # file = 'PGx_CTD_chem_x_gene_pgx-starts.csv'\n",
    "    # _df_data.to_csv(file, index=False)\n",
    "\n",
    "    ic(len(df_data), df_data.sentence.nunique())\n",
    "\n",
    "    file = 'PGx_CTD_chem_x_gene_sentence_same_sorted.csv'\n",
    "    df_data = df_data.sort_values(by=['sentence'])\n",
    "    df_data.to_csv(file, index=False)\n",
    "    return df_data\n",
    "\n",
    "\n",
    "def check_indexes(sorted_ents: list):\n",
    "    \"\"\"  \"\"\"\n",
    "    ## 1 same type NER are splitted as 2 parts; 2 NER types with overlap in sentence\n",
    "    former_ent = None\n",
    "    for entity in sorted_ents:\n",
    "        if former_ent:\n",
    "            former_ini = former_ent[0]\n",
    "            former_end = former_ent[1]\n",
    "            former_type = former_ent[3]\n",
    "            current_ini = entity[0]\n",
    "            current_end = entity[1]\n",
    "            current_type = entity[3]\n",
    "            if current_ini < former_end:\n",
    "                # ic(former_ent, entity)\n",
    "                # Allows overlap for different NER types.\n",
    "                # former_ent: (61, 67, 'MEK1/2', 'Gene')\n",
    "                # entity: (61, 77, 'MEK1/2 inhibitor', 'Chemical')\n",
    "                if former_type == current_type:\n",
    "                    ic(former_ent, entity)\n",
    "                    ## for high recall, not remove.\n",
    "                    # former_ent: (80, 109, 'in combination with cetuximab', 'Chemical')\n",
    "                    # entity: (100, 109, 'cetuximab', 'Chemical')\n",
    "                    # former_ent: (141, 158, 'chemotherapy with', 'Chemical')\n",
    "                    # entity: (141, 170, 'chemotherapy with carboplatin', 'Chemical')\n",
    "                    # if current_ini == former_ini:\n",
    "                        # former_ent: (20, 31, 'trastuzumab', 'Chemical')\n",
    "                        # entity: (20, 48, 'trastuzumab and capecitabine', 'Chemical')\n",
    "                        # former_ent: (20, 48, 'trastuzumab and capecitabine', 'Chemical')\n",
    "                        # entity: (36, 48, 'capecitabine', 'Chemical')\n",
    "                        # sorted_ents.remove(former_ent)\n",
    "                    # elif current_end < former_end:\n",
    "                        # former_ent: (102, 153, 'peginterferon ( PEG-IFN ) and ribavirin combination', 'Chemical')\n",
    "                        # entity: (132, 141, 'ribavirin', 'Chemical')\n",
    "                        # sorted_ents.remove(entity)\n",
    "        former_ent = entity\n",
    "\n",
    "\n",
    "def split_with_span_index(sentence: str):\n",
    "    words = sentence.split()\n",
    "    search_start = 0\n",
    "    out = []\n",
    "    for word in words:\n",
    "        start = sentence.find(word, search_start)\n",
    "        end = start + len(word)\n",
    "        out.append((word, start, end))\n",
    "        search_start = end\n",
    "    return out\n",
    "\n",
    "def add_context_words(sorted_ents, sent: str):\n",
    "    \"\"\"\n",
    "    special cases:\n",
    "        entity_name: ATRA\n",
    "        sent: (2) After treatment with ATRA, the fusion protein disappeared and PML protein resumed in NB4 cells, while in HL-60 and K562 cells there was no difference from control cells.\n",
    "\n",
    "        induced CYP1A1-dependent\n",
    "        MMP2/TIMP2 mRNA ratio\n",
    "        that PI-3K/Akt-mediated cyclin\n",
    "\n",
    "        entity: (13, 29, 'Arsenic trioxide', 'Chemical')\n",
    "        sent: CONCLUSIONS: Arsenic trioxide-induced renal\n",
    "    \"\"\"\n",
    "    extended_ents = []\n",
    "    all_words = split_with_span_index(sent)\n",
    "    for entity in sorted_ents:\n",
    "        entity_ini, entity_end, entity_name, entity_type = entity\n",
    "        leading_word = None\n",
    "        trailing_word = None\n",
    "        for word_i, (word, start, end) in enumerate(all_words):\n",
    "            # induced CYP1A1-dependent, CYP1A1 is gene\n",
    "            # (CYP1A1) is gene\n",
    "            if start in (entity_ini, entity_ini-1):\n",
    "                if start == entity_ini and word_i > 0:\n",
    "                    leading_word = all_words[word_i-1][0]\n",
    "                if start == entity_ini - 1:\n",
    "                    leading_word = word[:1]\n",
    "                if entity_end + 1 < end:\n",
    "                    trailing_word = word[len(entity_name):]\n",
    "            # MMP2/TIMP2 mRNA ratio\n",
    "            # with ATRA, the fusion\n",
    "            if not trailing_word:\n",
    "                if end == entity_end and word_i < len(all_words)-1:\n",
    "                    trailing_word = all_words[word_i+1][0]\n",
    "                    if not leading_word and start + 1 < entity_ini:\n",
    "                        leading_word = punc_at_ends.sub('', word[:entity_ini-start])\n",
    "                if end in (entity_end+1, entity_end+2):\n",
    "                    trailing_word = word[entity_end-start:]\n",
    "\n",
    "            # that PI-3K/Akt-mediated cyclinï¼Œ Akt at the middle\n",
    "            if start + 1 < entity_ini and entity_end + 1 < end:\n",
    "                if not leading_word:\n",
    "                    leading_word = punc_at_ends.sub('', word[:entity_ini-start])\n",
    "                if not trailing_word:\n",
    "                    ent_end_index_in_word = word.index(entity_name) + len(entity_name)\n",
    "                    trailing_word = punc_at_ends.sub('', word[ent_end_index_in_word:])\n",
    "            # entity: (13, 29, 'Arsenic trioxide', 'Chemical')\n",
    "            # sent: CONCLUSIONS: Arsenic trioxide-induced renal\n",
    "            if entity_end + 1 < end and not trailing_word and start < entity_end:\n",
    "                trailing_start_i = entity_end - start\n",
    "                trailing_word = punc_at_ends.sub('', word[trailing_start_i:])\n",
    "            # entity: (52, 77, 'cyclin-dependent kinase 4', 'Gene')\n",
    "            # sent: decreased cyclin-dependent kinase 4 kinase\n",
    "            if not trailing_word and start in (entity_end + 1, entity_end + 2):\n",
    "                trailing_word = word\n",
    "            # sent: cyclin D1/cyclin-dependent kinase 4 complexes\n",
    "            if not leading_word and start + 1 < entity_ini and entity_ini < end:\n",
    "                leading_end_i = len(word) - (end - entity_ini)\n",
    "                leading_word = punc_at_ends.sub('', word[:leading_end_i])\n",
    "\n",
    "        # the entity_ini at the start of sentence, or the entity_end at the end of sentence.\n",
    "        if ((not leading_word and entity_ini <= 1)\n",
    "            or (not trailing_word and (entity_end + 2 >= len(sent)))\n",
    "        ):\n",
    "            pass\n",
    "        elif not leading_word or not trailing_word:\n",
    "            ic(entity, sent)\n",
    "\n",
    "        # TODO del \"At the \"\n",
    "        if not leading_word:\n",
    "            leading_word = 'At the start of sentence'\n",
    "        if not trailing_word:\n",
    "            trailing_word = 'At the end of sentence'\n",
    "        extended_ents.append((leading_word, entity_name, trailing_word, entity_type))            \n",
    "    return extended_ents\n",
    "\n",
    "\n",
    "def merge_ner(x):\n",
    "    sent = x.sentence.tolist()[0]\n",
    "    lst_ents = set()\n",
    "    for ini, end, entity_name, entity_type in zip(x.entity_ini.tolist(), x.entity_end.tolist(), x.entity_name.tolist(), x.entity_type.tolist()):\n",
    "        if pd.isna(ini):\n",
    "            continue\n",
    "        entity_in_sent = sent[ini:end]\n",
    "        if entity_in_sent != entity_name:\n",
    "            # ic(entity_in_sent, entity_name, ini, end, sent)\n",
    "            if sent[ini: ini+len(entity_name)] == entity_name:\n",
    "                end = ini+len(entity_name)\n",
    "                lst_ents.add((ini, end, entity_name, entity_type))\n",
    "        else:\n",
    "            lst_ents.add((ini, end, entity_name, entity_type))\n",
    "    sorted_ents = sorted(lst_ents, key=lambda x: (x[0], x[1]))\n",
    "\n",
    "    # check_indexes(sorted_ents)\n",
    "    # sorted_ents = add_context_words(sorted_ents, sent)\n",
    "    return pd.Series([sorted_ents])\n",
    "\n",
    "\n",
    "df_data = read_chem_x_gene()\n",
    "df_data_ner = df_data.groupby(by=[\"sentence\"]).apply(lambda x: merge_ner(x)).reset_index().rename(columns={0: \"entity_info\"})\n",
    "ic(df_data_ner.columns.to_list())\n",
    "df_data_ner = df_data_ner.merge(df_data[[\"uid\", \"sentence\"]].drop_duplicates(), on=[\"sentence\"])\n",
    "df_data_ner.drop_duplicates(subset=[\"sentence\"])\n",
    "ic(len(df_data_ner))\n",
    "merged_ner_file = 'PGx_CTD_chem_x_gene_merged_ner.csv'\n",
    "df_data_ner.to_csv(merged_ner_file, index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence', 'llm_data']\n",
      "{\"conversation_id\": \"pgx_747\", \"category\": \"NER\", \"conversation\": [{\"human\": \"( NZB x NZW ) F1 mice respond to immunization with phosphorylcholine with a response that is largely encoded by the VH1 gene of the S107 family .\\n---------------\\nplease extract all Chemical and Gene in the above text, Gene includes gene or protein, excluding Limited variation, Genomic variation, Genomic factor, Haplotype.Chemical includes chemical and drug, excluding disease.The output format should be '<leading word in sentence, entity name, trailing word in sentence, entity type>' .\", \"assistant\": \"<with, phosphorylcholine, with, Chemical>, <the, VH1, gene, Gene>, <the, S107 family, ., Gene>\"}]}\n",
      "\n",
      "{\"conversation_id\": \"21145\", \"category\": \"NER\", \"conversation\": [{\"human\": \"(2) After treatment with ATRA, the fusion protein disappeared and PML protein resumed in NB4 cells, while in HL-60 and K562 cells there was no difference from control cells.\\n---------------\\nplease extract all Chemical and Gene in the above text, Gene includes gene or protein, excluding Limited variation, Genomic variation, Genomic factor, Haplotype.Chemical includes chemical and drug, excluding disease.The output format should be '<leading word in sentence, entity name, trailing word in sentence, entity type>' .\", \"assistant\": \"<with, ATRA, ,, Chemical>, <and, PML, protein, Gene>\"}]}\n",
      "\n",
      "{'conversation_id': 'pgx_747', 'category': 'NER', 'conversation': [{'human': \"( NZB x NZW ) F1 mice respond to immunization with phosphorylcholine with a response that is largely encoded by the VH1 gene of the S107 family .\\n---------------\\nplease extract all Chemical and Gene in the above text, Gene includes gene or protein, excluding Limited variation, Genomic variation, Genomic factor, Haplotype.Chemical includes chemical and drug, excluding disease.The output format should be '<leading word in sentence, entity name, trailing word in sentence, entity type>' .\", 'assistant': '<with, phosphorylcholine, with, Chemical>, <the, VH1, gene, Gene>, <the, S107 family, ., Gene>'}]}\n"
     ]
    }
   ],
   "source": [
    "def create_data(x):\n",
    "    # uid = x.pmid.tolist()[0]\n",
    "    # question = (\n",
    "    #    \"{sentence}\\n\"\n",
    "    #    \"---------------\\n\"\n",
    "    #    \"please extract all Herbs in the above text, \"\n",
    "    #    \"Herbs includes Chinese medicine, fruits, plants, medical plants. \"\n",
    "    #    \"Format your answer in the form of <entity name, entity type>.\")\n",
    "\n",
    "    # TODO the entity names should be output in the order of their appearance in the sentence amd the output should be a list of tuples, with the format of (leading word in sentence, entity name, trailing word in sentence, entity type).\n",
    "    question = (\n",
    "       \"{sentence}\\n\"\n",
    "       \"---------------\\n\"\n",
    "       \"please extract all Chemical and Gene in the above text, \"\n",
    "       \"Gene includes gene or protein, excluding Limited variation, Genomic variation, Genomic factor, Haplotype.\"\n",
    "       \"Chemical includes chemical and drug, excluding disease.\"\n",
    "    #    \"The output format should be '<entity name, entity span, entity type>' .\"\n",
    "    #    \"The output format should be '<entity name, starting position of entity name, entity type>' .\"\n",
    "       \"The output format should be '<entity name, entity type>' .\"\n",
    "        #    \"The output format should be '<starting index in sentence, ending index in sentence, entity name, entity type>' .\"\n",
    "    #    \"The output format should be '<leading word in sentence, entity name, trailing word in sentence, entity type>' .\"\n",
    "       )\n",
    "\n",
    "    lst_qa = []\n",
    "    sentence = x.sentence.tolist()[0]\n",
    "    uid = x.uid.tolist()[0]\n",
    "    question = question.format(sentence=sentence)\n",
    "    for entities in x.entity_info:\n",
    "        ans = []\n",
    "        for entity_name in entities:\n",
    "            if pd.isna(entity_name[-2]):\n",
    "                continue\n",
    "            # ans.append(f\"<{entity_name[-2]}, Herb>\")\n",
    "            # ans.append(f\"<{entity_name[-2]}, {entity_name[0]}, {entity_name[-1]}>\")\n",
    "            # ans.append(f\"<{entity_name[-2]}, {entity_name[-1]}>\")\n",
    "            # ans.append(f\"<{entity_name[0]}, {entity_name[1]}, {entity_name[2]}, {entity_name[3]}>\")\n",
    "            ans.append(f\"<{entity_name[2]}, {entity_name[3]}>\")\n",
    "            \n",
    "        # dict_qa = {\n",
    "        #     \"human\": question,\n",
    "        #     \"assistant\": \"|#|\".join(ans)\n",
    "        #     }\n",
    "        # lst_qa.append(dict_qa)\n",
    "        \n",
    "    return {\n",
    "            \"conversation_id\": uid,\n",
    "            \"category\": \"NER\",\n",
    "            \"conversation\": [{\n",
    "                                \"human\": question,\n",
    "                                \"assistant\": \", \".join(ans)\n",
    "                            }]\n",
    "    }\n",
    "\n",
    "\n",
    "df = df_data_ner.groupby(by=[\"sentence\"]).apply(lambda x: create_data(x))\n",
    "df = df.reset_index().rename(columns={0:\"llm_data\"})\n",
    "print(df.columns.to_list())\n",
    "\n",
    "jsonl_file = 'chem_gene_with_leading_trailing_words.jsonl'\n",
    "with open(jsonl_file, 'w', encoding='utf-8') as f:\n",
    "    for data in df.llm_data.values.tolist():\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "print(data[0])\n",
    "print(data[1])\n",
    "d = json.loads(data[0])\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_data_ner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/qcdong/codes/Firefly/data_process/preprocess/ner/create_sft_data.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bremote123/home/qcdong/codes/Firefly/data_process/preprocess/ner/create_sft_data.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(df_data_ner\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mto_list())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bremote123/home/qcdong/codes/Firefly/data_process/preprocess/ner/create_sft_data.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(df_data_ner\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mentity_info)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bremote123/home/qcdong/codes/Firefly/data_process/preprocess/ner/create_sft_data.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_ner\u001b[39m(row):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_data_ner' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_data_ner.columns.to_list())\n",
    "print(df_data_ner.iloc[0].entity_info)\n",
    "\n",
    "\n",
    "def check_ner(row):\n",
    "    \"\"\" Not need to check here, but ahead \"\"\"\n",
    "    sentence = row.sentence\n",
    "    # print(type(sentence), sentence)\n",
    "    for entities in row.entity_info:\n",
    "        # print(entities, type(entities))\n",
    "        ini, end, entity_name, entity_type = entities\n",
    "        int_ini = int(ini)\n",
    "        int_end = int(end)\n",
    "        if pd.isna(ini):\n",
    "            # print(sentence)\n",
    "            continue\n",
    "        ent = sentence[int_ini: int_end]\n",
    "        if ent != entity_name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# df_data_ner[\"check\"] = df_data_ner.apply(lambda x: check_ner(x), axis=1)\n",
    "# ner_false = df_data_ner[df_data_ner[\"check\"] == False]\n",
    "# if len(ner_false) > 0:\n",
    "#     ner_false.to_csv(\"ner_false.csv\", index=False)\n",
    "# print(len(ner_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path('test.csv').exists():\n",
    "    _df = pd.read_csv('test.csv')\n",
    "    print(_df)\n",
    "    _df.dropna(inplace=True)\n",
    "    print(_df)\n",
    "    _df = pd.read_csv('test.csv', dtype=str)\n",
    "    print(_df)\n",
    "    _df.dropna(inplace=True)\n",
    "    print(_df)\n",
    "    # pd auto convert 'nan' str to np.nan, even with dytpe=str\n",
    "    _df.to_json('test.json', orient='records',)\n",
    "    d = {'a': 1, 'b': 22}\n",
    "    df1 = pd.DataFrame.from_dict(d, orient='index')\n",
    "    print(df1)\n",
    "    print(df1.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"conversation_id\": \"pgx_747\", \"category\": \"NER\", \"conversation\": [{\"human\": \"( NZB x NZW ) F1 mice respond to immunization with phosphorylcholine with a response that is largely encoded by the VH1 gene of the S107 family .\\n---------------\\nplease extract all Chemical and Gene in the above text, Gene includes gene or protein, excluding Limited variation, Genomic variation, Genomic factor, Haplotype.Chemical includes chemical and drug, excluding disease.The output format should be '<leading word in sentence, entity name, trailing word in sentence, entity type>' .\", \"assistant\": \"<with, phosphorylcholine, with, Chemical>, <the, VH1, gene, Gene>, <the, S107 family, ., Gene>\"}]}\n",
      "\n",
      "{\"conversation_id\": \"21145\", \"category\": \"NER\", \"conversation\": [{\"human\": \"(2) After treatment with ATRA, the fusion protein disappeared and PML protein resumed in NB4 cells, while in HL-60 and K562 cells there was no difference from control cells.\\n---------------\\nplease extract all Chemical and Gene in the above text, Gene includes gene or protein, excluding Limited variation, Genomic variation, Genomic factor, Haplotype.Chemical includes chemical and drug, excluding disease.The output format should be '<leading word in sentence, entity name, trailing word in sentence, entity type>' .\", \"assistant\": \"<with, ATRA, the, Chemical>, <and, PML, protein, Gene>\"}]}\n",
      "\n",
      "{'conversation_id': 'pgx_747', 'category': 'NER', 'conversation': [{'human': \"( NZB x NZW ) F1 mice respond to immunization with phosphorylcholine with a response that is largely encoded by the VH1 gene of the S107 family .\\n---------------\\nplease extract all Chemical and Gene in the above text, Gene includes gene or protein, excluding Limited variation, Genomic variation, Genomic factor, Haplotype.Chemical includes chemical and drug, excluding disease.The output format should be '<leading word in sentence, entity name, trailing word in sentence, entity type>' .\", 'assistant': '<with, phosphorylcholine, with, Chemical>, <the, VH1, gene, Gene>, <the, S107 family, ., Gene>'}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# file = 'chem_gene_with_indexes.json'\n",
    "# with open(file, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(df.llm_data.values.tolist(), f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# with open(file, 'r', encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "# print(len(data))\n",
    "# print(data[0])\n",
    "# print(data[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ll",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
